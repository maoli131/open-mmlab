{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "370789f1-a728-41c8-982b-efbb0ef3aa91",
   "metadata": {},
   "source": [
    "# Weights and Bias Integration\n",
    "\n",
    "Following the official tutorial of `wandb`, this notebook integrates `wandb` with a multilayer preceptron model trained on Fashion-MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5410fa56-b306-4f7f-8eeb-9a25eeb98654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "\n",
    "# from tqdm.notebook import tqdm # progress bar\n",
    "\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
    "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
    "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
    "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
    "\n",
    "# Device Configuration\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fcfe39-130a-400e-984d-14d8f86864eb",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "We must login to wandb account, in order to record our training on the platform's dashborad. Make sure to install wandb library in our virtual conda environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b16c1cb6-7c0e-4d3f-98c3-7774894a5684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5dfd76-8c30-41d9-a1f3-1cb7a3611434",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define Data Loading and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf031035-ef1f-4b1a-951b-ffa71fbb7f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and testing data with config (slice)\n",
    "def get_data(slice=5, train=True):\n",
    "    \n",
    "    full_dataset = datasets.FashionMNIST(\n",
    "        root=\"data\",\n",
    "        train=train,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "    # equiv to slicing iwth [::slice]\n",
    "    sub_dataset = Subset(full_dataset, indices=range(0, len(full_dataset), slice))\n",
    "    \n",
    "    return sub_dataset\n",
    "\n",
    "# Make the dataloader with config (dataset, batch_size\n",
    "def make_loader(dataset, batch_size):\n",
    "    \n",
    "    loader = DataLoader(dataset=dataset, batch_size=batch_size)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ee64716-aecc-4594-acd4-4e36eba53433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model: a simple multilayer preceptron\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, classes=10):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef19a84-30ca-4a33-8471-df001c214058",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define Training Logic\n",
    "\n",
    "`wandb.watch` will log the gradients and the parameters of your model, every `log_freq` steps of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "250de5a2-92f2-45c1-867c-73cda9d88aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer, config):\n",
    "    \n",
    "    # Tell wandb to watch what the model gets up to: gradients, weights, and more!\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "    \n",
    "    # Run training and track with wandb\n",
    "    total_batches = len(loader) * config.epochs\n",
    "    example_ct = 0  # number of examples seen\n",
    "    batch_ct = 0\n",
    "    for epoch in range(config.epochs):\n",
    "        for _, (images, labels) in enumerate(loader):\n",
    "\n",
    "            loss = train_batch(images, labels, model, optimizer, criterion)\n",
    "            example_ct +=  len(images)\n",
    "            batch_ct += 1\n",
    "\n",
    "            # Report metrics every 25th batch\n",
    "            if ((batch_ct + 1) % 25) == 0:\n",
    "                train_log(loss, example_ct, epoch)\n",
    "\n",
    "def train_batch(images, labels, model, optimizer, criterion):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    # Forward pass \n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Backward pass \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Step with optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e830e783-cf52-460a-a79d-c397c5dfd495",
   "metadata": {},
   "source": [
    "`wandb.log` records the reported metrics to their server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5b3fcf0-aa02-42d9-b89c-b2df66930304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_log(loss, example_ct, epoch):\n",
    "    # Where the magic happens\n",
    "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
    "    print(f\"Loss after \" + str(example_ct).zfill(5) + f\" examples: {loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee64fd46-8b17-40ae-936b-aa54269518b7",
   "metadata": {},
   "source": [
    "## Define Testing Logic\n",
    "\n",
    "Once the model is done training, we want to test it: run it against some fresh data from production.\n",
    "\n",
    "We can save the model's architecture and final parameters to disk. We'll `export` our model in the\n",
    "[Open Neural Network eXchange (ONNX) format](https://onnx.ai/).\n",
    "\n",
    "Passing that filename to `wandb.save` ensures that the model parameters are saved to W&B's servers: no more losing track of which `.h5` or `.pb` corresponds to which training runs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1689ebf9-54fd-47ff-8deb-2382d27248ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    # Run the model on some test examples\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f\"Accuracy of the model on the {total} \" +\n",
    "              f\"test images: {100 * correct / total}%\")\n",
    "        \n",
    "        wandb.log({\"test_accuracy\": correct / total})\n",
    "\n",
    "    # Save the model in the exchangeable ONNX format\n",
    "    torch.onnx.export(model, images, \"model.onnx\")\n",
    "    wandb.save(\"model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd5b072-4ee7-4f3d-bfa4-b536b06f950d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define the experiment and pipeline\n",
    "\n",
    "### Config\n",
    "\n",
    "Hyperparameters and metadata for our model is stored in a dictionary `config`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9862a6b6-89a1-421c-bd24-79d528bbd3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    epochs=5,\n",
    "    classes=10,\n",
    "    batch_size=64,\n",
    "    learning_rate=0.001,\n",
    "    dataset=\"Fashion-MNIST\",\n",
    "    architecture=\"MLP\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a7683e-17cc-4496-b719-706c85f913b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Make\n",
    "\n",
    "To ensure the values we chose and logged are always the ones that get used\n",
    "in our model, we use the `wandb.config` copy of your object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24e6405e-cc87-4b22-b8e5-30c764db93f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make(config):\n",
    "    # Make the data\n",
    "    train, test = get_data(train=True), get_data(train=False)\n",
    "    train_loader = make_loader(train, batch_size=config.batch_size)\n",
    "    test_loader = make_loader(test, batch_size=config.batch_size)\n",
    "\n",
    "    # Make the model\n",
    "    model = MLP(config.classes).to(device)\n",
    "\n",
    "    # Make the loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(), lr=config.learning_rate)\n",
    "    \n",
    "    return model, train_loader, test_loader, criterion, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc2c5c1-3a59-4153-b6ac-ee9a6a18c59c",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "\n",
    "The overall pipeline is structured as the following:\n",
    "1. we first `make` a model, plus associated data and optimizer, then\n",
    "2. we `train` the model accordingly and finally\n",
    "3. `test` it to see how training went."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e77c575b-60ec-40f5-ab8b-fceaa2912636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(hyperparameters):\n",
    "\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"pytorch-demo\", config=hyperparameters):\n",
    "      \n",
    "        # access all HPs through wandb.config, so logging matches execution!\n",
    "        config = wandb.config\n",
    "\n",
    "        # make the model, data, and optimization problem\n",
    "        model, train_loader, test_loader, criterion, optimizer = make(config)\n",
    "        print(model)\n",
    "\n",
    "        # and use them to train the model\n",
    "        train(model, train_loader, criterion, optimizer, config)\n",
    "\n",
    "        # and test its final performance\n",
    "        test(model, test_loader)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e6acff6-600f-4631-a28b-3963d5748946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/maoli131/pytorch-demo/runs/1t8cccru\" target=\"_blank\">toasty-sponge-4</a></strong> to <a href=\"https://wandb.ai/maoli131/pytorch-demo\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Loss after 01536 examples: 2.301\n",
      "Loss after 03136 examples: 2.308\n",
      "Loss after 04736 examples: 2.292\n",
      "Loss after 06336 examples: 2.293\n",
      "Loss after 07936 examples: 2.278\n",
      "Loss after 09536 examples: 2.271\n",
      "Loss after 11136 examples: 2.268\n",
      "Loss after 12704 examples: 2.267\n",
      "Loss after 14304 examples: 2.264\n",
      "Loss after 15904 examples: 2.259\n",
      "Loss after 17504 examples: 2.267\n",
      "Loss after 19104 examples: 2.258\n",
      "Loss after 20704 examples: 2.259\n",
      "Loss after 22304 examples: 2.241\n",
      "Loss after 23904 examples: 2.246\n",
      "Loss after 25472 examples: 2.243\n",
      "Loss after 27072 examples: 2.237\n",
      "Loss after 28672 examples: 2.228\n",
      "Loss after 30272 examples: 2.232\n",
      "Loss after 31872 examples: 2.222\n",
      "Loss after 33472 examples: 2.212\n",
      "Loss after 35072 examples: 2.215\n",
      "Loss after 36640 examples: 2.226\n",
      "Loss after 38240 examples: 2.195\n",
      "Loss after 39840 examples: 2.217\n",
      "Loss after 41440 examples: 2.184\n",
      "Loss after 43040 examples: 2.192\n",
      "Loss after 44640 examples: 2.210\n",
      "Loss after 46240 examples: 2.207\n",
      "Loss after 47840 examples: 2.196\n",
      "Loss after 49408 examples: 2.166\n",
      "Loss after 51008 examples: 2.160\n",
      "Loss after 52608 examples: 2.166\n",
      "Loss after 54208 examples: 2.181\n",
      "Loss after 55808 examples: 2.146\n",
      "Loss after 57408 examples: 2.165\n",
      "Loss after 59008 examples: 2.158\n",
      "Accuracy of the model on the 2000 test images: 48.1%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 72499... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 2.56MB of 2.56MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆███████</td></tr><tr><td>loss</td><td>██▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▄▃▃▄▄▃▂▂▂▃▁▂▂</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>2.15772</td></tr><tr><td>test_accuracy</td><td>0.481</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">toasty-sponge-4</strong>: <a href=\"https://wandb.ai/maoli131/pytorch-demo/runs/1t8cccru\" target=\"_blank\">https://wandb.ai/maoli131/pytorch-demo/runs/1t8cccru</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211207_021419-1t8cccru/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build, train and analyze the model with the pipeline\n",
    "model = model_pipeline(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tutorial",
   "language": "python",
   "name": "tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
